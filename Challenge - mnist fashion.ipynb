{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_mnist(kind='train')\n",
    "X_test, y_test = load_mnist(kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io, filters\n",
    "from PIL import Image as Image\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> 1. ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000029D9CD90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000029D9CD90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: nan - accuracy: 0.0988\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x234de1d0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(512, input_shape=(784,), activation=\"relu\"))\n",
    "model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(128, activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000022B46E18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000022B46E18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 3558.9429 - accuracy: 0.1119\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3015 - accuracy: 0.1124\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3012 - accuracy: 0.1124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b8bc18>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU - Tweaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A. Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000006B8C6D90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000006B8C6D90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: nan - accuracy: 0.0984\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x700d76d8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#512 - 256 - 128 - 64 - 10\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(512, input_shape=(784,), activation=\"relu\"))\n",
    "model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(128, activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: nan\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "score = model_relu.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000715048C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000715048C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.09870s - loss: nan\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7151b2b0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 128 - 64 - 10\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
    "#model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(128, activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: nan\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "score = model_relu.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### B. Number of nerons in the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000766111E0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000766111E0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: nan - accuracy: 0.0989\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x765f4d68>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 256 - 64 - 10\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
    "#model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: nan\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "score = model_relu.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000007DB91C80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000007DB91C80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: nan - accuracy: 0.0988\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7dbc09e8>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#128 - 128 - 64 - 10\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "#model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(128, activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: nan\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "score = model_relu.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### C. Different batch sizes during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000053FA76A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000053FA76A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 10s 159us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 9s 157us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 153us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x52335128>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 128 - 64 - 10\n",
    "#batch_size = 8\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
    "#model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(128, activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=8, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: nan\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "score = model_relu.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000058B26730> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000058B26730> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: nan - accuracy: 0.0986         \n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x58b29e10>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 128 - 64 - 10\n",
    "#batch_size = 784\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
    "#model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(128, activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=784, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: nan\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "score = model_relu.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000005C08D1E0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000005C08D1E0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: nan - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5c072c88>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 128 - 64 - 10\n",
    "#batch_size = 392\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
    "#model_relu.add(Dense(256, activation=\"relu\"))\n",
    "model_relu.add(Dense(128, activation=\"relu\"))\n",
    "model_relu.add(Dense(64, activation=\"relu\"))\n",
    "model_relu.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# setting verbose=1 prints out some results after each epoch\n",
    "model_relu.fit(X_train, y_train, batch_size=392, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: nan\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "score = model_relu.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Very low accuracy overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> 2. Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000046D09158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000046D09158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.8775 - accuracy: 0.7573\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.4577 - accuracy: 0.8777\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.3836 - accuracy: 0.8928\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.3380 - accuracy: 0.9053\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.3148 - accuracy: 0.9095\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.3012 - accuracy: 0.9135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2768 - accuracy: 0.9201\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2731 - accuracy: 0.9202\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2583 - accuracy: 0.9243\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2549 - accuracy: 0.9248\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2414 - accuracy: 0.9301\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2443 - accuracy: 0.9286\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2391 - accuracy: 0.9292\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2278 - accuracy: 0.9331\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2209 - accuracy: 0.9337\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2132 - accuracy: 0.9361\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2044 - accuracy: 0.9396\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.1993 - accuracy: 0.9401\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.2036 - accuracy: 0.9379\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.1971 - accuracy: 0.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x46cebe80>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(128, input_shape = (784,), activation = 'tanh'))\n",
    "model_tanh.add(Dense(64, activation = 'tanh'))\n",
    "model_tanh.add(Dense(10, activation = 'softmax'))\n",
    "model_tanh.summary()\n",
    "\n",
    "model_tanh.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_tanh.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh - Tweaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A. Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_166 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000738F61E0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000738F61E0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.7146 - accuracy: 0.8133\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3444 - accuracy: 0.9071\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2753 - accuracy: 0.9241\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2422 - accuracy: 0.9315\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2174 - accuracy: 0.9372\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2028 - accuracy: 0.9408\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1933 - accuracy: 0.9443\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1810 - accuracy: 0.9479\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1798 - accuracy: 0.9470\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1682 - accuracy: 0.9513\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1654 - accuracy: 0.9507\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1633 - accuracy: 0.9513\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1553 - accuracy: 0.9530\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1483 - accuracy: 0.9548\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1459 - accuracy: 0.9563\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1466 - accuracy: 0.9562\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1401 - accuracy: 0.9578\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1348 - accuracy: 0.9586\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1326 - accuracy: 0.9603\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1306 - accuracy: 0.9608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x738d0f98>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#512 - 256 - 128 - 64 - 10\n",
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(512, input_shape = (784,), activation = 'tanh'))\n",
    "model_tanh.add(Dense(256, activation = 'tanh'))\n",
    "model_tanh.add(Dense(128, activation = 'tanh'))\n",
    "model_tanh.add(Dense(64, activation = 'tanh'))\n",
    "model_tanh.add(Dense(10, activation = 'softmax'))\n",
    "model_tanh.summary()\n",
    "\n",
    "model_tanh.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_tanh.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.14694015924781562\n",
      "Test accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "score = model_tanh.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 242,762\n",
      "Trainable params: 242,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000073FE0EA0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000073FE0EA0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8412 - accuracy: 0.7782\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.4183 - accuracy: 0.8886\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3324 - accuracy: 0.9083\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2948 - accuracy: 0.9170\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2692 - accuracy: 0.9232\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2498 - accuracy: 0.9285\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2351 - accuracy: 0.9317\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2250 - accuracy: 0.9354\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2135 - accuracy: 0.9371\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2049 - accuracy: 0.9392\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2040 - accuracy: 0.9401\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1968 - accuracy: 0.9417\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1850 - accuracy: 0.9448\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1810 - accuracy: 0.9457\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1729 - accuracy: 0.9472\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1714 - accuracy: 0.9479\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1681 - accuracy: 0.9491\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1596 - accuracy: 0.9522\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1543 - accuracy: 0.9534\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1550 - accuracy: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x74b11d30>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 128 - 64 - 10\n",
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(256, input_shape = (784,), activation = 'tanh'))\n",
    "#model_tanh.add(Dense(256, activation = 'tanh'))\n",
    "model_tanh.add(Dense(128, activation = 'tanh'))\n",
    "model_tanh.add(Dense(64, activation = 'tanh'))\n",
    "model_tanh.add(Dense(10, activation = 'softmax'))\n",
    "model_tanh.summary()\n",
    "\n",
    "model_tanh.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_tanh.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.16630791448652743\n",
      "Test accuracy: 0.9499\n"
     ]
    }
   ],
   "source": [
    "score = model_tanh.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>layers: 512 - 256 - 128 - 64 - 10 performs best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### B. Number of nerons in the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 349,642\n",
      "Trainable params: 349,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000075D56D90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000075D56D90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.7342 - accuracy: 0.8052\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.3679 - accuracy: 0.8990\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.3062 - accuracy: 0.9140\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2693 - accuracy: 0.9214\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2538 - accuracy: 0.9253\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2321 - accuracy: 0.9316\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2241 - accuracy: 0.9339\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2141 - accuracy: 0.9366\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2076 - accuracy: 0.9378\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2020 - accuracy: 0.9394\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1902 - accuracy: 0.9418\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.1844 - accuracy: 0.9438\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1857 - accuracy: 0.9430\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1783 - accuracy: 0.9458\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1743 - accuracy: 0.9466\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1726 - accuracy: 0.9476\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1717 - accuracy: 0.9491\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1645 - accuracy: 0.9494\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1666 - accuracy: 0.9493\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.1680 - accuracy: 0.9487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x75d83d30>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 256 - 256 - 64 - 10\n",
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(256, input_shape = (784,), activation = 'tanh'))\n",
    "model_tanh.add(Dense(256, activation = 'tanh'))\n",
    "model_tanh.add(Dense(256, activation = 'tanh'))\n",
    "model_tanh.add(Dense(64, activation = 'tanh'))\n",
    "model_tanh.add(Dense(10, activation = 'softmax'))\n",
    "model_tanh.summary()\n",
    "\n",
    "model_tanh.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_tanh.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.18029669236540793\n",
      "Test accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "score = model_tanh.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 142,410\n",
      "Trainable params: 142,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000007EF6DC80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000007EF6DC80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.8949 - accuracy: 0.7639\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4442 - accuracy: 0.8779\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.3678 - accuracy: 0.8949\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3335 - accuracy: 0.9034\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3181 - accuracy: 0.9056\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3050 - accuracy: 0.9098\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2905 - accuracy: 0.9122\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2747 - accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2673 - accuracy: 0.9202\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2582 - accuracy: 0.9235\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2531 - accuracy: 0.9232\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2518 - accuracy: 0.9247\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2438 - accuracy: 0.9256\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2344 - accuracy: 0.9288\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2339 - accuracy: 0.9290\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2216 - accuracy: 0.9328\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2153 - accuracy: 0.9345\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2069 - accuracy: 0.9367\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2095 - accuracy: 0.9350\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2073 - accuracy: 0.9365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ef9ba90>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#128 - 128 - 128 - 64 - 10\n",
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(128, input_shape = (784,), activation = 'tanh'))\n",
    "model_tanh.add(Dense(128, activation = 'tanh'))\n",
    "model_tanh.add(Dense(128, activation = 'tanh'))\n",
    "model_tanh.add(Dense(64, activation = 'tanh'))\n",
    "model_tanh.add(Dense(10, activation = 'softmax'))\n",
    "model_tanh.summary()\n",
    "\n",
    "model_tanh.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_tanh.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.21648189881145954\n",
      "Test accuracy: 0.9337\n"
     ]
    }
   ],
   "source": [
    "score = model_tanh.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Best to use narrowing down number of neurons in the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### C. Different batch sizes during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_185 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 125,898\n",
      "Trainable params: 125,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000008DD0FAE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000008DD0FAE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 2.2669 - accuracy: 0.2027\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 2.1878 - accuracy: 0.4348\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 2.0676 - accuracy: 0.5476\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.8809 - accuracy: 0.6075\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.6549 - accuracy: 0.6438\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.4298 - accuracy: 0.6839\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2188 - accuracy: 0.7311\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0398 - accuracy: 0.7709\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8993 - accuracy: 0.8001\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7919 - accuracy: 0.8244\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7068 - accuracy: 0.8429\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6380 - accuracy: 0.8566\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.5817 - accuracy: 0.8684\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.5341 - accuracy: 0.8772\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4949 - accuracy: 0.8855\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4615 - accuracy: 0.8906\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4329 - accuracy: 0.8965\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4094 - accuracy: 0.9002\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3884 - accuracy: 0.9043\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3700 - accuracy: 0.9072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x8dd3e860>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#128 - 128 - 64 - 10\n",
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(128, input_shape = (784,), activation = 'sigmoid'))\n",
    "#model_sig.add(Dense(256, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(128, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.21648189881145954\n",
      "Test accuracy: 0.9337\n"
     ]
    }
   ],
   "source": [
    "score = model_tanh.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_189 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000007399F950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000007399F950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.3378 - accuracy: 0.6275\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.7491 - accuracy: 0.8285\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.5683 - accuracy: 0.8666\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.4739 - accuracy: 0.8871\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.4124 - accuracy: 0.8990\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3697 - accuracy: 0.9081\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3377 - accuracy: 0.9145\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3113 - accuracy: 0.9208\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2900 - accuracy: 0.9258\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2713 - accuracy: 0.9298\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2547 - accuracy: 0.9349\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2413 - accuracy: 0.9376\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2286 - accuracy: 0.9407\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2178 - accuracy: 0.9429\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2078 - accuracy: 0.9454\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1980 - accuracy: 0.9487\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1899 - accuracy: 0.9511\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1810 - accuracy: 0.9538\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1725 - accuracy: 0.9561\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1663 - accuracy: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5637bd68>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#512 - 256 - 128 - 64 - 10\n",
    "#batch_size = full size (784)\n",
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(512, input_shape = (784,), activation = 'tanh'))\n",
    "model_tanh.add(Dense(256, activation = 'tanh'))\n",
    "model_tanh.add(Dense(128, activation = 'tanh'))\n",
    "model_tanh.add(Dense(64, activation = 'tanh'))\n",
    "model_tanh.add(Dense(10, activation = 'softmax'))\n",
    "model_tanh.summary()\n",
    "\n",
    "model_tanh.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_tanh.fit(X_train, y_train, batch_size = 784, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.22146317300498486\n",
      "Test accuracy: 0.9372\n"
     ]
    }
   ],
   "source": [
    "score = model_tanh.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_194 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000076CB8268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000076CB8268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 1.0788 - accuracy: 0.7190\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.5167 - accuracy: 0.8764\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.3928 - accuracy: 0.9004\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.3316 - accuracy: 0.9135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2942 - accuracy: 0.9223\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2619 - accuracy: 0.9301\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2396 - accuracy: 0.9352\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2224 - accuracy: 0.9402\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2058 - accuracy: 0.9439\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1930 - accuracy: 0.9477\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1797 - accuracy: 0.9515\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1702 - accuracy: 0.9536\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1630 - accuracy: 0.9555\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1543 - accuracy: 0.9574\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1480 - accuracy: 0.9594\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1404 - accuracy: 0.9617\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1351 - accuracy: 0.9630\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1273 - accuracy: 0.9656\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1240 - accuracy: 0.9668\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.1168 - accuracy: 0.9687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x584dd940>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#512 - 256 - 128 - 64 - 10\n",
    "#batch_size = 392\n",
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(512, input_shape = (784,), activation = 'tanh'))\n",
    "model_tanh.add(Dense(256, activation = 'tanh'))\n",
    "model_tanh.add(Dense(128, activation = 'tanh'))\n",
    "model_tanh.add(Dense(64, activation = 'tanh'))\n",
    "model_tanh.add(Dense(10, activation = 'softmax'))\n",
    "model_tanh.summary()\n",
    "\n",
    "model_tanh.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_tanh.fit(X_train, y_train, batch_size = 392, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.15923606711328028\n",
      "Test accuracy: 0.9513\n"
     ]
    }
   ],
   "source": [
    "score = model_tanh.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> 3. Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000004733AD08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000004733AD08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9300 - accuracy: 0.5624\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 1.3500 - accuracy: 0.7868\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.9790 - accuracy: 0.8329\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.7557 - accuracy: 0.8611\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.6176 - accuracy: 0.8773\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.5261 - accuracy: 0.8888\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.4634 - accuracy: 0.8970\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.4168 - accuracy: 0.9039\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.3831 - accuracy: 0.9088\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.3566 - accuracy: 0.9131\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.3348 - accuracy: 0.9172\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.3179 - accuracy: 0.9198\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.3020 - accuracy: 0.9239\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2882 - accuracy: 0.9263\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2769 - accuracy: 0.9287\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2682 - accuracy: 0.9305\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2582 - accuracy: 0.9329\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2490 - accuracy: 0.9342\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2407 - accuracy: 0.9363\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.2344 - accuracy: 0.9382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4736d6d8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(128, input_shape = (784,), activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid - Tweaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### A. Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 575,050\n",
      "Trainable params: 575,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000004F7507B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000004F7507B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 2.3082 - accuracy: 0.1141\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 2.2844 - accuracy: 0.1272\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.2718 - accuracy: 0.1566\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.2548 - accuracy: 0.2217\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.2292 - accuracy: 0.3112\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.1866 - accuracy: 0.4236\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 2.1094 - accuracy: 0.4934\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.9723 - accuracy: 0.5236\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.7832 - accuracy: 0.5409\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.5959 - accuracy: 0.5782\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.4317 - accuracy: 0.6166\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.2887 - accuracy: 0.6562\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.1620 - accuracy: 0.6975\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.0461 - accuracy: 0.7444\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.9408 - accuracy: 0.7787\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.8493 - accuracy: 0.8052\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.7721 - accuracy: 0.8247\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.7067 - accuracy: 0.8413\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.6500 - accuracy: 0.8546\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.6001 - accuracy: 0.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x4f73b128>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#512 - 256 - 128 - 64 - 10\n",
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(512, input_shape = (784,), activation = 'sigmoid'))\n",
    "model_sig.add(Dense(256, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(128, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.5784798972129822\n",
      "Test accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "score = model_sig.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 242,762\n",
      "Trainable params: 242,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000643BA158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000643BA158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.2600 - accuracy: 0.2526\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1293 - accuracy: 0.4909\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9411 - accuracy: 0.5719\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6908 - accuracy: 0.6483\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.4268 - accuracy: 0.7121\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1914 - accuracy: 0.7634\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0049 - accuracy: 0.8021\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.8609 - accuracy: 0.8304\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.7476 - accuracy: 0.8519\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.6569 - accuracy: 0.8673\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.5845 - accuracy: 0.8780\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.5260 - accuracy: 0.8862\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.4798 - accuracy: 0.8934\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.4425 - accuracy: 0.8990\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.4120 - accuracy: 0.9041\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3863 - accuracy: 0.9083\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3643 - accuracy: 0.9116\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3453 - accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3295 - accuracy: 0.9191\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3143 - accuracy: 0.9215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x643a05f8>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 128 - 64 - 10\n",
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(256, input_shape = (784,), activation = 'sigmoid'))\n",
    "#model_sig.add(Dense(256, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(128, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.3172828525543213\n",
      "Test accuracy: 0.9207\n"
     ]
    }
   ],
   "source": [
    "score = model_sig.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### B. Number of nerons in the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 283,850\n",
      "Trainable params: 283,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000006609BA60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000000006609BA60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 2.2622 - accuracy: 0.2279\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.1389 - accuracy: 0.5110\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.9579 - accuracy: 0.6081\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.7085 - accuracy: 0.6670\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.4202 - accuracy: 0.7182\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1476 - accuracy: 0.7700\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.9369 - accuracy: 0.8114\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.7848 - accuracy: 0.8405\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.6735 - accuracy: 0.8604\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.5895 - accuracy: 0.8749\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.5256 - accuracy: 0.8853\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.4759 - accuracy: 0.8933\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.4376 - accuracy: 0.8988\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.4059 - accuracy: 0.9036\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3794 - accuracy: 0.9083\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3578 - accuracy: 0.9111\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3387 - accuracy: 0.9155\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3226 - accuracy: 0.9186\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3085 - accuracy: 0.9209\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2955 - accuracy: 0.9237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x660d22e8>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#256 - 256 - 64 - 10\n",
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(256, input_shape = (784,), activation = 'sigmoid'))\n",
    "#model_sig.add(Dense(256, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(256, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.3005338268995285\n",
      "Test accuracy: 0.9222\n"
     ]
    }
   ],
   "source": [
    "score = model_sig.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_124 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 125,898\n",
      "Trainable params: 125,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000661100D0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000000661100D0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 2.2859 - accuracy: 0.1878\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 2.1858 - accuracy: 0.4121\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 2.0608 - accuracy: 0.5278\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.8675 - accuracy: 0.5866\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.6346 - accuracy: 0.6355\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.4154 - accuracy: 0.6842\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2228 - accuracy: 0.7271\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0559 - accuracy: 0.7632\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9186 - accuracy: 0.7948\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8093 - accuracy: 0.8225\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7224 - accuracy: 0.8424\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6520 - accuracy: 0.8565\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.5932 - accuracy: 0.8691\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.5437 - accuracy: 0.8777\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.5025 - accuracy: 0.8845\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4677 - accuracy: 0.8907\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4389 - accuracy: 0.8954\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4118 - accuracy: 0.9014\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3905 - accuracy: 0.9049\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3716 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6bafdc50>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#128 - 128 - 64 - 10\n",
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(128, input_shape = (784,), activation = 'sigmoid'))\n",
    "#model_sig.add(Dense(256, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(128, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 128, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.3650088099956512\n",
      "Test accuracy: 0.909\n"
     ]
    }
   ],
   "source": [
    "score = model_sig.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### C. Different batch sizes during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_128 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000058F91400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000058F91400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 8s 135us/sample - loss: 0.8156 - accuracy: 0.8118\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.4449 - accuracy: 0.8831\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.4110 - accuracy: 0.8884\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s 138us/sample - loss: 0.4136 - accuracy: 0.8797\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s 135us/sample - loss: 0.4239 - accuracy: 0.8737\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.4285 - accuracy: 0.8706\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.4207 - accuracy: 0.8730\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.4306 - accuracy: 0.8691\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.4183 - accuracy: 0.8711\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4068 - accuracy: 0.8745\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3952 - accuracy: 0.8788\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3741 - accuracy: 0.8843\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3636 - accuracy: 0.8883\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3728 - accuracy: 0.8832\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3578 - accuracy: 0.8899\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3345 - accuracy: 0.8958\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.3287 - accuracy: 0.8982\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3422 - accuracy: 0.8934\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.3461 - accuracy: 0.8922\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3425 - accuracy: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x527a61d0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_size = 8\n",
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(128, input_shape = (784,), activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 8, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.34047010437250136\n",
      "Test accuracy: 0.8945\n"
     ]
    }
   ],
   "source": [
    "score = model_sig.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000053F3FC80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000053F3FC80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 2.3421 - accuracy: 0.1802\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 2.1168 - accuracy: 0.4039\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.9981 - accuracy: 0.5288\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.8920 - accuracy: 0.5960\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.7926 - accuracy: 0.6324\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.6958 - accuracy: 0.6654\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.6023 - accuracy: 0.6898\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.5144 - accuracy: 0.7122\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.4319 - accuracy: 0.7334\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.3552 - accuracy: 0.7492\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 1.2845 - accuracy: 0.7674\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 1.2193 - accuracy: 0.7824\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.1591 - accuracy: 0.7947\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.1034 - accuracy: 0.8056\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.0522 - accuracy: 0.8175\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 1.0047 - accuracy: 0.8264\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 0s 6us/sample - loss: 0.9606 - accuracy: 0.8343\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 0.9200 - accuracy: 0.8424\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 0.8826 - accuracy: 0.8475\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 0.8480 - accuracy: 0.8530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x53f810b8>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_size = 784\n",
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(128, input_shape = (784,), activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 784, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.8303745219230652\n",
      "Test accuracy: 0.859\n"
     ]
    }
   ],
   "source": [
    "score = model_sig.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_134 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000064B272F0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000000064B272F0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 2.1553 - accuracy: 0.3595\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8945 - accuracy: 0.5738\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.7005 - accuracy: 0.6553\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.5340 - accuracy: 0.6978\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.3873 - accuracy: 0.7341\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.2578 - accuracy: 0.7629\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.1441 - accuracy: 0.7871\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 1.0444 - accuracy: 0.8070\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.9568 - accuracy: 0.8238\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.8798 - accuracy: 0.8370\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.8129 - accuracy: 0.8489\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 0.7547 - accuracy: 0.8593\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.7034 - accuracy: 0.8657\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 0.6597 - accuracy: 0.8726\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.6207 - accuracy: 0.8783\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.5867 - accuracy: 0.8826\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.5565 - accuracy: 0.8867\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.5320 - accuracy: 0.8897\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.5067 - accuracy: 0.8927\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 0.4856 - accuracy: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x64b0bd30>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_size = 392\n",
    "model_sig = Sequential()\n",
    "model_sig.add(Dense(128, input_shape = (784,), activation = 'sigmoid'))\n",
    "model_sig.add(Dense(64, activation = 'sigmoid'))\n",
    "model_sig.add(Dense(10, activation = 'softmax'))\n",
    "model_sig.summary()\n",
    "\n",
    "model_sig.compile(optimizer = 'sgd', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "model_sig.fit(X_train, y_train, batch_size = 392, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4782491657733917\n",
      "Test accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "score = model_sig.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Best Model: Tanh</b><br>\n",
    "\n",
    "<b>tweaks:</b>\n",
    "> 5 Layers: 512 - 256 - 128 - 64 - 10 <br>\n",
    "> Batch Size = 128 <br>\n",
    "<br>\n",
    "\n",
    "> Scores:<br>\n",
    "> Test score: 0.14694015924781562 <br>\n",
    "> Test accuracy: 0.9556 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
